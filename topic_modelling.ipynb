{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling on Provincial News Releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.critical)\n",
    "\n",
    "# LDA\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# Stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Regex\n",
    "import re\n",
    "\n",
    "# Lemmatization\n",
    "import spacy\n",
    "import fr_core_news_sm\n",
    "\n",
    "# Printing model topics\n",
    "from pprint import pprint\n",
    "\n",
    "# Model Visualization\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "# For plotting coherence values\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# From source_scraping.py\n",
    "from source_scraping import load_province\n",
    "\n",
    "# Dates\n",
    "from datetime import datetime\n",
    "\n",
    "# Utils\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Text\n",
    "\n",
    "In order to prepare the articles for our LDA model, they are be split into individual words, stripped of \"stop words\" that contribute little information, and lemmatized (replaced by their roots. “Swimming” becomes “swim”, for instance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(texts, stop_words):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        - `texts`\n",
    "            a list of documents\n",
    "        - `stop_words`\n",
    "            a list of words to be removed from each document in `texts`\n",
    "    \n",
    "    Returns: a list of documents that does not contain any element of `stop_words`\n",
    "    \"\"\"\n",
    "    return [[word for word in doc if word not in stop_words] for doc in texts]\n",
    "\n",
    "def clean_(doc):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        - `doc`\n",
    "            a list of words\n",
    "    \n",
    "    Returns: a documents with new lines and consecutive spaces replaced by single spaces\n",
    "    \"\"\"\n",
    "    new_doc = [re.sub(r'\\s+', ' ', word) for word in doc]\n",
    "    # More filters if necessary\n",
    "    return new_doc\n",
    "\n",
    "def clean(texts):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        - `texts`\n",
    "            a list of documents broken into words\n",
    "    \n",
    "    Returns: a list of documents with new lines and consecutive spaces replaced by single spaces\n",
    "    \"\"\"\n",
    "    return [clean_(doc) for doc in texts]\n",
    "\n",
    "def texts_to_words(texts):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        - `texts`\n",
    "            a list of documents\n",
    "    \n",
    "    Yields: a document broken into words and with punctuation removed\n",
    "    \"\"\"\n",
    "    for doc in corpus:\n",
    "        yield gensim.utils.simple_preprocess(doc, deacc=True)\n",
    "\n",
    "def lemmatize(texts, allowed_postags=['NOUN', 'ADJ', 'VERB'], lang='english'):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        - `texts`\n",
    "            a list of documents broken into words\n",
    "        - `allowed_postags`\n",
    "            a list of the parts of speech to be preserved (e.g ['NOUN', 'ADJ'])\n",
    "        - `lang`\n",
    "            the language in which the document is written\n",
    "    \n",
    "    Returns: a list of documents with words replaced by their lemmas and removed if they do not constitute a part of speech indicated in `allowed_postags`\n",
    "    \"\"\"\n",
    "    \n",
    "    # French for Quebec\n",
    "    nlp = spacy.load('en', disable=['parser', 'ner']) if lang == 'english' else fr_core_news_sm.load(disable=['parser', 'ner'])\n",
    "    return [[token.lemma_ for token in nlp(\" \".join(doc)) if token.pos_ in allowed_postags] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts, min_count=5, threshold=100):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        - `texts`\n",
    "            a list of documents broken into words\n",
    "    \n",
    "    Returns: a list of documents with words arranged into bigrams where applicable\n",
    "    \"\"\"\n",
    "    bigram = Phrases(texts, min_count=min_count, threshold=threshold)\n",
    "    bigram_mod = Phraser(bigram)\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "    \n",
    "# def make_trigrams(texts):\n",
    "#     return make_bigrams(make_bigrams(texts)) I'm not sure if this one behaves correctly\n",
    "\n",
    "def custom_preprocess(texts, stop_words, allowed_postags, bigrams=True, lang='english'):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        - `texts`\n",
    "            a list of documents broken into words\n",
    "        - `stop_words`\n",
    "            a list of words to be removed from each document in `texts`\n",
    "        - `allowed_postags`\n",
    "            a list of the parts of speech to be preserved (e.g ['NOUN', 'ADJ'])\n",
    "        - `bigrams`\n",
    "            a boolean indicating whether or not to form bigrams from the words in the texts\n",
    "        - `lang`\n",
    "            the language in which the texts are written\n",
    "\n",
    "    \n",
    "    Returns: a list of preprocessed documents. A result of calling the functions `text_to_words()`, `clean()`, (optionally) `make_bigrams()`, and `lemmatize()` in succession.\n",
    "    \"\"\"\n",
    "    partially_processed = clean(list(texts_to_words(texts)))\n",
    "    return lemmatize(make_bigrams(partially_processed) if bigrams else partially_processed, allowed_postags=allowed_postags, lang=lang)\n",
    "\n",
    "def dict_corpus(texts):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        - `texts`\n",
    "            a list of documents broken into words\n",
    "    \n",
    "    Returns: a dictionary and corpus for use in LDA models\n",
    "    \"\"\"\n",
    "    id2word = corpora.Dictionary(texts)\n",
    "    corpus = [id2word.doc2bow(text) for text in texts]\n",
    "    return id2word, corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding a Good Topic Number\n",
    "\n",
    "In order to create a model that produces understandable topics, the number of topics should be tweaked so as to produce topics that are coherent. The following function tries various values for the topic number (specified by the <code>n_topic_range</code> parameter) and outputs the best model, a list of all the models, and a list of all the $C_v$ coherence values.\n",
    "\n",
    "The <code>plot</code> parameter specifies whether or not the function should also graph the coherence values against the number of topics for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model(n_topic_range, texts, id2word, corpus, random_state=42, plot=True, verbose=False):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        - `n_topic_range`\n",
    "            a range of values for the `num_topics` parameter of a gensim LDA model to try\n",
    "        - `texts`\n",
    "            a list of documents broken into words\n",
    "        - `id2word`\n",
    "            a dictionary containing word encodings\n",
    "        - `corpus`\n",
    "            the result of mapping each word in `texts` to its value in `id2word`\n",
    "        - `random_state` \n",
    "            a random state for use in a gensim LDA model\n",
    "        - `plot`\n",
    "            a boolean specifying whether or not to plot coherence values against each `num_topics` value\n",
    "        - `verbose`\n",
    "            a boolean specifying whether or not to print updates\n",
    "    \n",
    "    Returns: a tuple containing the best model, the list of all models attempted, and a list of all coherence values obtained, respectively.\n",
    "    \"\"\"\n",
    "    models = []\n",
    "    coherence_vals = []\n",
    "        \n",
    "    for n_topics in n_topic_range:\n",
    "        \n",
    "        # Print percentage progress\n",
    "        if verbose:\n",
    "            diff = max(n_topic_range) - min(n_topic_range)\n",
    "            print(str(round(100 * (n_topics - min(n_topic_range)) / diff, 1)) + \"% done\")\n",
    "        \n",
    "        lda_model = LdaModel(corpus=corpus,\n",
    "                            id2word=id2word,\n",
    "                            num_topics=n_topics,\n",
    "                            random_state=random_state,\n",
    "                            update_every=1,\n",
    "                            chunksize=100,\n",
    "                            passes=10,\n",
    "                            alpha='auto',\n",
    "                            per_word_topics=True\n",
    "                            )\n",
    "        co_model = CoherenceModel(lda_model, texts=texts, dictionary=id2word, coherence=\"c_v\")\n",
    "        coherence = co_model.get_coherence()\n",
    "                \n",
    "        models.append(lda_model)\n",
    "        coherence_vals.append(coherence)\n",
    "\n",
    "    if plot:\n",
    "        plt.plot(n_topic_range, coherence_vals, 'b')\n",
    "        plt.show()\n",
    "    \n",
    "    return models[np.argmax(coherence_vals)], models, coherence_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Visualization\n",
    "\n",
    "The <code>pyLDAvis</code> library provides neat visualizations of LDA models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, corpus, id2word):\n",
    "        \"\"\"\n",
    "    Parameters:\n",
    "        - `model`\n",
    "            a gensim LDA model\n",
    "        - `corpus`\n",
    "            the corpus on which the model was trained\n",
    "        - `id2word`\n",
    "            the dictionary on which the model was trained\n",
    "    \n",
    "    Returns: a tuple containing the best model, the list of all models attempted, and a list of all coherence values obtained, respectively.\n",
    "    \"\"\"\n",
    "    pyLDAvis.enable_notebook()\n",
    "    return pyLDAvis.gensim.prepare(model, corpus, id2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full LDA Pipeline\n",
    "\n",
    "All together now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_model(province, doc_attrib='source_full_text', start_date=datetime(2020, 1, 1), end_date=datetime.today(), bigram=True, allowed_postags=['NOUN', 'VERB', 'ADJ'], n_topic_range=range(2, 40, 3), plot=True, random_state=42, verbose=False):\n",
    "    \"\"\"\n",
    "    Creates an LDA model with a given province's article base\n",
    "    \n",
    "    Returns:\n",
    "        a dictionary containing the best model, full model list, list of coherence values, the id2word dictionary, and corpus\n",
    "    \"\"\"\n",
    "    \n",
    "    lang = 'french' if province.lower() == 'quebec' else 'english'\n",
    "    \n",
    "    df = load_province(province.lower(), verbose)\n",
    "    \n",
    "    # Filter within date range\n",
    "    df = df[pd.to_datetime(df['start_date']) > start_date]\n",
    "    df = df[pd.to_datetime(df['start_date']) < end_date]\n",
    "    \n",
    "    texts = df[doc_attrib]\n",
    "    \n",
    "    if verbose: print(\"\\nPreprocessing Texts\\n\")\n",
    "    texts = custom_preprocess(texts, stopwords.words(lang), allowed_postags=allowed_postags, bigrams=True, lang=lang)\n",
    "    \n",
    "    id2word, corpus = dict_corpus(texts)\n",
    "    \n",
    "    if verbose: print(\"\\nFinding Best n_topics Values\\n\")\n",
    "    model, model_list, co_vals = find_best_model(n_topic_range, texts, id2word, corpus, random_state, plot, verbose)\n",
    "    \n",
    "    return {\n",
    "        'best_model' : model, \n",
    "        'model_list' : model_list, \n",
    "        'coherence_vals' : co_vals, \n",
    "        'id2word' : id2word, \n",
    "        'corpus' : corpus,\n",
    "        'texts' : texts,\n",
    "        'visualization' : visualize_model(model, corpus, id2word)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lda_information = lda_model('alberta', start_date=datetime(2020, 3, 11), verbose=True)\n",
    "lda_information['visualization']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bitb7deb3926a5743b595e3b44ad861ac00"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
