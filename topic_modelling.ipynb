{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling with Province News Releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.critical)\n",
    "\n",
    "# LDA\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# Stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Regex\n",
    "import re\n",
    "\n",
    "# Lemmatization\n",
    "import spacy\n",
    "import fr_core_news_sm\n",
    "\n",
    "# Printing model topics\n",
    "from pprint import pprint\n",
    "\n",
    "# Model Visualization\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "# For plotting coherence values\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# From source_scraping.py\n",
    "from source_scraping import load_province\n",
    "\n",
    "# Utils\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Text\n",
    "\n",
    "In order to prepare the articles for our LDA model, they are be split into individual words, stripped of \"stop words\" that contribute little information, and lemmatized (replaced by their roots. “Swimming” becomes “swim”, for instance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(texts, stop_words):\n",
    "    return [[word for word in doc if word not in stop_words] for doc in texts]\n",
    "\n",
    "def clean_(doc):\n",
    "    new_doc = [re.sub(r'\\s+', ' ', word) for word in doc]\n",
    "    # More filters if necessary\n",
    "    return new_doc\n",
    "\n",
    "def clean(texts):\n",
    "    return [clean_(doc) for doc in texts]\n",
    "\n",
    "def texts_to_words(corpus):\n",
    "    for doc in corpus:\n",
    "        yield gensim.utils.simple_preprocess(doc, deacc=True)\n",
    "\n",
    "def lemmatize(texts, allowed_postags=['NOUN', 'ADJ', 'VERB'], lang='english'):\n",
    "    # French for Quebec\n",
    "    nlp = spacy.load('en', disable=['parser', 'ner']) if lang == 'english' else fr_core_news_sm.load(disable=['parser', 'ner'])\n",
    "    return [[token.lemma_ for token in nlp(\" \".join(doc)) if token.pos_ in allowed_postags] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    bigram = Phrases(texts, min_count=5, threshold=100)\n",
    "    bigram_mod = Phraser(bigram)\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "    \n",
    "# def make_trigrams(texts):\n",
    "#     return make_bigrams(make_bigrams(texts)) I'm not sure if this one behaves correctly\n",
    "\n",
    "def custom_preprocess(texts, stop_words, allowed_postags, bigrams=True, lang='english'):\n",
    "    partially_processed = clean(list(texts_to_words(texts)))\n",
    "    return lemmatize(make_bigrams(partially_processed) if bigrams else partially_processed, allowed_postags=allowed_postags, lang=lang)\n",
    "\n",
    "def dict_corpus(texts):\n",
    "    id2word = corpora.Dictionary(texts)\n",
    "    corpus = [id2word.doc2bow(text) for text in texts] # Essentially `texts`, but encoded (I think)\n",
    "    return id2word, corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding a Good Topic Number\n",
    "\n",
    "In order to create a model that produces understandable topics, the number of topics should be tweaked so as to produce topics that are coherent. The following function tries various values for the topic number (specified by the <code>n_topic_range</code> parameter) and outputs the best model, a list of all the models, and a list of all the $C_v$ coherence values.\n",
    "\n",
    "The <code>plot</code> parameter specifies whether or not the function should also graph the coherence values against the number of topics for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model(n_topic_range, texts, id2word, corpus, random_state=42, plot=True, verbose=False):\n",
    "    models = []\n",
    "    coherence_vals = []\n",
    "        \n",
    "    for n_topics in n_topic_range:\n",
    "        \n",
    "        # Print percentage progress\n",
    "        if verbose:\n",
    "            diff = max(n_topic_range) - min(n_topic_range)\n",
    "            print(str(int(1000 * (n_topics - min(n_topic_range)) / diff) / 10) + \"% done\")\n",
    "        \n",
    "        lda_model = LdaModel(corpus=corpus,\n",
    "                            id2word=id2word,\n",
    "                            num_topics=n_topics,\n",
    "                            random_state=random_state,\n",
    "                            update_every=1,\n",
    "                            chunksize=100,\n",
    "                            passes=10,\n",
    "                            alpha='auto',\n",
    "                            per_word_topics=True\n",
    "                            )\n",
    "        co_model = CoherenceModel(lda_model, texts=texts, dictionary=id2word, coherence=\"c_v\")\n",
    "        coherence = co_model.get_coherence()\n",
    "                \n",
    "        models.append(lda_model)\n",
    "        coherence_vals.append(coherence)\n",
    "\n",
    "    if plot:\n",
    "        plt.plot(n_topic_range, coherence_vals, 'b')\n",
    "        plt.show()\n",
    "    \n",
    "    return models[np.argmax(coherence_vals)], models, coherence_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Visualization\n",
    "\n",
    "The <code>pyLDAvis</code> library provides neat visualizations of LDA models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, corpus, id2word):\n",
    "    pyLDAvis.enable_notebook()\n",
    "    vis = pyLDAvis.gensim.prepare(model, corpus, id2word)\n",
    "    pyLDAvis.show(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full LDA Pipeline\n",
    "\n",
    "All together now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_model(province, doc_attrib='source_full_text', bigram=True, allowed_postags=['NOUN', 'VERB', 'ADJ'], n_topic_range=range(2, 40, 3), plot=True, random_state=42, verbose=False, vis=True):\n",
    "    lang = 'french' if province.lower() == 'quebec' else 'english'\n",
    "    \n",
    "    texts = load_province(province.lower(), verbose)[doc_attrib]\n",
    "    \n",
    "    if verbose: print(\"\\nPreprocessing Texts\\n\")\n",
    "    texts = custom_preprocess(texts, stopwords.words(lang), allowed_postags=allowed_postags, bigrams=True, lang=lang)\n",
    "    \n",
    "    id2word, corpus = dict_corpus(texts)\n",
    "    \n",
    "    if verbose: print(\"\\nFinding Best n_topics Values\\n\")\n",
    "    model, model_list, co_vals = find_best_model(n_topic_range, texts, id2word, corpus, random_state, plot, verbose)\n",
    "\n",
    "    if vis:\n",
    "        visualize_model(model, corpus, id2word)\n",
    "        \n",
    "    return model, model_list, co_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "    \n",
    "q_model, _, _ = lda_model('quebec', verbose=True) # Achieves coherence score of 0.60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that while a warning will suggest using <code>pyLDAvis.display()</code> instead of <code>pyLDAvis.show()</code>, it doesn't seem to work. Click [here](https://github.com/bmabey/pyLDAvis/issues/101) for more info."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bitb7deb3926a5743b595e3b44ad861ac00"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
